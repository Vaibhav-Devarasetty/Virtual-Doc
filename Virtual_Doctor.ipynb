{"cells":[{"cell_type":"markdown","source":["Virtual Doctor\n","\n","Language Model, which does diagnosis and provides recommended next steps, just by inputting symptoms\n","\n","Text pre-processing, Causal Language Modeling (CLM), Bert, GPT2\n","\n","Encoding the given text by tokenizers and Bert and then using multihead attention model, inputing that to GPT and then training GPT to give Doctor Diagnosis, and recommend next steps."],"metadata":{"id":"iyFlTAmw1gQV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsqnYZjbG-cj","outputId":"bbdb43d3-63cd-4e9f-db6a-eeeb8783ed7c","executionInfo":{"status":"ok","timestamp":1646443843487,"user_tz":-330,"elapsed":3990,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgRmSFGRDFsE"},"outputs":[],"source":["! pip -q install transformers==2.9.0 gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYQHZPV4hoxP"},"outputs":[],"source":["#hide\n","# Imports\n","\n","\n","\"\"\"\n","Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n","GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n","using a masked language modeling (MLM) loss.\n","\"\"\"\n","\n","import glob\n","import logging\n","import os\n","import pickle\n","import random\n","import re\n","import shutil\n","from typing import Dict, List, Tuple\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm.notebook import tqdm, trange\n","\n","from pathlib import Path\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","\n","try:\n","    from torch.utils.tensorboard import SummaryWriter\n","except ImportError:\n","    from tensorboardX import SummaryWriter\n","\n","# Configs\n","logger = logging.getLogger(__name__)\n","\n","MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n","MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Co8wGlRHDa0H"},"outputs":[],"source":["#collapse\n","# Args to allow for easy convertion of python script to notebook\n","class Args():\n","    def __init__(self):\n","        self.output_dir = 'output'\n","        self.model_type = 'gpt2'\n","        self.model_name_or_path = 'microsoft/DialoGPT-small'\n","        self.config_name = 'microsoft/DialoGPT-small'\n","        self.tokenizer_name = 'microsoft/DialoGPT-small'\n","        self.cache_dir = 'cached'\n","        self.block_size = 512\n","        self.do_train = True\n","        self.do_eval = True\n","        self.evaluate_during_training = False\n","        self.per_gpu_train_batch_size = 4\n","        self.per_gpu_eval_batch_size = 4\n","        self.gradient_accumulation_steps = 1\n","        self.learning_rate = 5e-5\n","        self.weight_decay = 0.0\n","        self.adam_epsilon = 1e-8\n","        self.max_grad_norm = 1.0\n","        self.num_train_epochs = 3\n","        self.max_steps = -1\n","        self.warmup_steps = 0\n","        self.logging_steps = 1000\n","        self.save_steps = 3500\n","        self.save_total_limit = None\n","        self.eval_all_checkpoints = False\n","        self.no_cuda = False\n","        self.overwrite_output_dir = True\n","        self.overwrite_cache = True\n","        self.should_continue = False\n","        self.seed = 42\n","        self.local_rank = -1\n","        self.fp16 = False\n","        self.fp16_opt_level = 'O1'\n","\n","args = Args()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDsPJg9wDoDw"},"outputs":[],"source":["df=pd.read_csv('/content/drive/MyDrive/MedDialog/MedDialog/MedDialog_csv_files/icliniq_dialogue.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"Vl7-jN8IHcCo","outputId":"01680d7f-d31d-4d49-e017-c8226bb3b9f2","executionInfo":{"status":"ok","timestamp":1646443847273,"user_tz":-330,"elapsed":13,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-c850e75e-b113-4647-99b3-aedb79771a83\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Description</th>\n","      <th>Patient</th>\n","      <th>Doctor</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q. What does abutment of the nerve root mean?</td>\n","      <td>patient: Hi doctor,I am just wondering what is...</td>\n","      <td>doctor: Hi. I have gone through your query wit...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Q. Every time I eat spicy food, I poop blood. ...</td>\n","      <td>patient: Hi doctor,I am a 26 year old male. I ...</td>\n","      <td>doctor: Hello. I have gone through your inform...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Q. Will Nano-Leo give permanent solution for e...</td>\n","      <td>patient: Hello doctor,I am 48 years old. I am ...</td>\n","      <td>doctor: Hi. For further doubts consult a sexol...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Q. Will Kalarchikai cure multiple ovarian cyst...</td>\n","      <td>patient: Hello doctor,I have multiple small cy...</td>\n","      <td>doctor: Hello. I just read your query. See Kal...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Q. I masturbate only by rubbing the tip of the...</td>\n","      <td>patient: Hi doctor,During masturbation I just ...</td>\n","      <td>doctor: Hi. For further doubts consult a sexol...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>20692</th>\n","      <td>Q. Brother-in-law got a stent for stomach canc...</td>\n","      <td>patient: Hi doctor,My brother-in-law has stoma...</td>\n","      <td>doctor: Hi. I understand your concern. For fur...</td>\n","    </tr>\n","    <tr>\n","      <th>20693</th>\n","      <td>Q. Having osteoporosis and spine fracture. How...</td>\n","      <td>patient: Hi doctor,I have osteoporosis and L3 ...</td>\n","      <td>doctor: Hi. I have gone through your message a...</td>\n","    </tr>\n","    <tr>\n","      <th>20694</th>\n","      <td>Q. How long should I take Humira?</td>\n","      <td>patient: Hi doctor,I am a 55 year old male. I ...</td>\n","      <td>doctor: Hello. For further information consult...</td>\n","    </tr>\n","    <tr>\n","      <th>20695</th>\n","      <td>Q. Tried withdrawal method and took I-pill. Am...</td>\n","      <td>patient: Hi doctor,I had unprotected sex and t...</td>\n","      <td>doctor: Hi. For further information consult an...</td>\n","    </tr>\n","    <tr>\n","      <th>20696</th>\n","      <td>Q. How to replace loose teeth with denture imp...</td>\n","      <td>patient: Hi doctor,I have very bad teeth and a...</td>\n","      <td>doctor: Hello. For further information consult...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20697 rows Ã— 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c850e75e-b113-4647-99b3-aedb79771a83')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c850e75e-b113-4647-99b3-aedb79771a83 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c850e75e-b113-4647-99b3-aedb79771a83');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                             Description  \\\n","0          Q. What does abutment of the nerve root mean?   \n","1      Q. Every time I eat spicy food, I poop blood. ...   \n","2      Q. Will Nano-Leo give permanent solution for e...   \n","3      Q. Will Kalarchikai cure multiple ovarian cyst...   \n","4      Q. I masturbate only by rubbing the tip of the...   \n","...                                                  ...   \n","20692  Q. Brother-in-law got a stent for stomach canc...   \n","20693  Q. Having osteoporosis and spine fracture. How...   \n","20694                  Q. How long should I take Humira?   \n","20695  Q. Tried withdrawal method and took I-pill. Am...   \n","20696  Q. How to replace loose teeth with denture imp...   \n","\n","                                                 Patient  \\\n","0      patient: Hi doctor,I am just wondering what is...   \n","1      patient: Hi doctor,I am a 26 year old male. I ...   \n","2      patient: Hello doctor,I am 48 years old. I am ...   \n","3      patient: Hello doctor,I have multiple small cy...   \n","4      patient: Hi doctor,During masturbation I just ...   \n","...                                                  ...   \n","20692  patient: Hi doctor,My brother-in-law has stoma...   \n","20693  patient: Hi doctor,I have osteoporosis and L3 ...   \n","20694  patient: Hi doctor,I am a 55 year old male. I ...   \n","20695  patient: Hi doctor,I had unprotected sex and t...   \n","20696  patient: Hi doctor,I have very bad teeth and a...   \n","\n","                                                  Doctor  \n","0      doctor: Hi. I have gone through your query wit...  \n","1      doctor: Hello. I have gone through your inform...  \n","2      doctor: Hi. For further doubts consult a sexol...  \n","3      doctor: Hello. I just read your query. See Kal...  \n","4      doctor: Hi. For further doubts consult a sexol...  \n","...                                                  ...  \n","20692  doctor: Hi. I understand your concern. For fur...  \n","20693  doctor: Hi. I have gone through your message a...  \n","20694  doctor: Hello. For further information consult...  \n","20695  doctor: Hi. For further information consult an...  \n","20696  doctor: Hello. For further information consult...  \n","\n","[20697 rows x 3 columns]"]},"metadata":{},"execution_count":12}],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MrfEzyLiHRkY"},"outputs":[],"source":["df=df[['Doctor','Patient']]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"paXtgm5dEJzj","outputId":"727d275e-ae06-4d48-8e49-7313a3a0555d","executionInfo":{"status":"ok","timestamp":1646443847274,"user_tz":-330,"elapsed":12,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-98bab4d3-3b11-46d8-b88b-39ec65e7adc2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doctor</th>\n","      <th>Patient</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>7559</th>\n","      <td>doctor: Hi. Well, not only the LDL (low-densit...</td>\n","      <td>patient: Hi doctor,I am a 28-year-old male. My...</td>\n","    </tr>\n","    <tr>\n","      <th>14401</th>\n","      <td>doctor: Hello. Considering the inflammatory bo...</td>\n","      <td>patient: Hello doctor,I had abdominal pain six...</td>\n","    </tr>\n","    <tr>\n","      <th>1809</th>\n","      <td>doctor: Hello. The gums looked blanched or whi...</td>\n","      <td>patient: Hi doctor, I have a question about my...</td>\n","    </tr>\n","    <tr>\n","      <th>12817</th>\n","      <td>doctor: Hi. For further information consult a ...</td>\n","      <td>patient: Hi doctor,I have aÂ small lump on the ...</td>\n","    </tr>\n","    <tr>\n","      <th>6987</th>\n","      <td>doctor: Hi. After carefully reading your compl...</td>\n","      <td>patient: Hello doctor,For a couple of months, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98bab4d3-3b11-46d8-b88b-39ec65e7adc2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-98bab4d3-3b11-46d8-b88b-39ec65e7adc2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-98bab4d3-3b11-46d8-b88b-39ec65e7adc2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                  Doctor  \\\n","7559   doctor: Hi. Well, not only the LDL (low-densit...   \n","14401  doctor: Hello. Considering the inflammatory bo...   \n","1809   doctor: Hello. The gums looked blanched or whi...   \n","12817  doctor: Hi. For further information consult a ...   \n","6987   doctor: Hi. After carefully reading your compl...   \n","\n","                                                 Patient  \n","7559   patient: Hi doctor,I am a 28-year-old male. My...  \n","14401  patient: Hello doctor,I had abdominal pain six...  \n","1809   patient: Hi doctor, I have a question about my...  \n","12817  patient: Hi doctor,I have aÂ small lump on the ...  \n","6987   patient: Hello doctor,For a couple of months, ...  "]},"metadata":{},"execution_count":14}],"source":["df = df.dropna()\n","trn_df, val_df = train_test_split(df, test_size = 0.2)\n","trn_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKtMch3DEN_X"},"outputs":[],"source":["#hide\n","from collections import Counter\n","from statistics import mean, median, stdev\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oa9CfewnE8AV"},"outputs":[],"source":["#collapse\n","def get_counter_and_lens(data, tokenizer):\n","    flatten = lambda l: [item for sublist in l for item in sublist]\n","    toks = [tokenizer.tokenize(x) for x in data]\n","    \n","    return list(map(len, toks)), Counter(flatten(toks)), Counter(' '.join(data).split())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wqhMDd1jFFHf","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["a7211330437f499ebbb62766b475d7f0","b47bdb844079463cbeefebf365ed7bc2","fca5b45ccfef4ed88a31fcf37ec26263","a8920166d7c94ccc8c52b971076e59f1","dd5848ba096c4cd39d57e714679ffc3a","ad465b67670949579758ad0e305cfa4e","a42581ccc09c4bef9c2ca961761951a6","85a47e2bdfa040598b5af5cf8303723b","1a2574687c224a7ba2aac4006f36dbc5","cfabaa20f7564b29924273199b186dea","34045a64e62d4636a7adda0e50efb82a","31689cab58374e24a39c452dc1143079","f3753f2ddbdf4951bd7d5d5fd8a9e248","4ca0df277ba9498e91090faf1ed7910e","387444066e834ffa9d6707c07f9c1bdc","0c43a988e7c8426eab81eb4b84895414","43dcbbc32b3642f08b8a71ea0b7515ea","1b729157638c4c83b4f658a3708d6cb9","52040aad026548d3a503374df3187c78","a5a308162274422187f0556aaa66a107","aa90481a9d98486d8287a11e0ea477f7","73b1f42107ba44d7b96266bb18eaa979","62de908ed03c49e384582a3761081fb1","ac3c63b395574dca85c096aa2c0c840e","d57651c3cfb84c9fa1fd760092a48b08","21a83f0e03f44c4cbf3623c2ed7b9229","4568e5e114a240a4b0c09c4e7cfd3002","f45f5d19085843f4846924b2b11f625c","6ab6267d49e94383b17ce43ee9051e12","3ed21bde17d941089cd2a35c81134b79","e3ad32ccea414bc99e49ee6fd40c9b8d","d6e24f78d8294252b2cc930d67cc3c0a","2c0b69f3c24943c89f3e61d8f5d45b4f"]},"executionInfo":{"status":"ok","timestamp":1646443870929,"user_tz":-330,"elapsed":23665,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}},"outputId":"cb98bfaa-1ba9-4657-aeb3-7686760992ed"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7211330437f499ebbb62766b475d7f0","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/641 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31689cab58374e24a39c452dc1143079","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62de908ed03c49e384582a3761081fb1","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, cache_dir=args.cache_dir)\n","lens, tok_cnt, word_cnt = get_counter_and_lens(trn_df[df.columns].apply(lambda x: ' '.join(x.astype(str)), axis = 1), tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rW__Ru5KFQD1"},"outputs":[],"source":["#collapse\n","def plot_counts(counts, top_k = 30):\n","    labels, values = zip(*counts.most_common()[:top_k])\n","\n","    indexes = np.arange(len(labels))\n","    width = 1\n","    plt.figure(num=None, figsize=(22, 4), dpi=60, facecolor='w', edgecolor='k')\n","    plt.bar(indexes, values, width)\n","    plt.xticks(indexes + width * 0.5, labels)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"fHCZ7Pp1FTdM","outputId":"b26aa1cc-f21a-4793-e590-32a5ee5ad728","executionInfo":{"status":"ok","timestamp":1646443871936,"user_tz":-330,"elapsed":1013,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1320x240 with 1 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1320x240 with 1 Axes>"]},"metadata":{}}],"source":["plot_counts(tok_cnt, top_k = 30)\n","plot_counts(word_cnt, top_k = 30)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-wX5FacbFVW8"},"outputs":[],"source":["#collapse\n","def plot_hist(lens, n_bins = 50):\n","    n, bins, patches = plt.hist(lens, n_bins, facecolor='blue', alpha=0.9)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"9w-qMH3ZFa9T","outputId":"9337b984-ffa5-4de3-c066-9d0610a9ee67","executionInfo":{"status":"ok","timestamp":1646443871938,"user_tz":-330,"elapsed":13,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mean: 262.2090354532826, Median: 230, Standard Deviation: 151.36928445338555, 90th Percentile: 1908.0\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["print(f'Mean: {mean(lens)}, Median: {median(lens)}, Standard Deviation: {stdev(lens)}, 90th Percentile: {np.percentile(lens, 100)}')\n","plot_hist(lens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lkMAK_FbFc8P"},"outputs":[],"source":["#collapse\n","def construct_conv(row, tokenizer, eos = True):\n","    # from: https://stackoverflow.com/questions/952914/how-to-make-a-flat-list-out-of-list-of-lists\n","    flatten = lambda l: [item for sublist in l for item in sublist]\n","    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n","    conv = flatten(conv)\n","    return conv\n","\n","class ConversationDataset(Dataset):\n","    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n","\n","        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n","\n","        directory = args.cache_dir\n","        cached_features_file = os.path.join(\n","            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n","        )\n","\n","        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","            logger.info(\"Loading features from cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"rb\") as handle:\n","                self.examples = pickle.load(handle)\n","        else:\n","            logger.info(\"Creating features from dataset file at %s\", directory)\n","\n","            self.examples = []\n","            for _, row in df.iterrows():\n","                conv = construct_conv(row, tokenizer)\n","                if len(conv) > block_size: continue\n","                self.examples.append(conv)\n","\n","            # Note that we are loosing the last truncated example here for the sake of simplicity (no padding)\n","            # If your dataset is small, first you should loook for a bigger one :-) and second you\n","            # can change this behavior by adding (model specific) padding.\n","\n","            logger.info(\"Saving features into cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"wb\") as handle:\n","                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, item):\n","        return torch.tensor(self.examples[item], dtype=torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"prGma5uTFj6x"},"outputs":[],"source":["#hide\n","# Cacheing and storing of data/checkpoints\n","\n","def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n","    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n","\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n","    ordering_and_checkpoint_path = []\n","\n","    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n","\n","    for path in glob_checkpoints:\n","        if use_mtime:\n","            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n","        else:\n","            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n","            if regex_match and regex_match.groups():\n","                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n","\n","    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n","    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n","    return checkpoints_sorted\n","\n","\n","def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n","    if not args.save_total_limit:\n","        return\n","    if args.save_total_limit <= 0:\n","        return\n","\n","    # Check if we should delete older checkpoint(s)\n","    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n","    if len(checkpoints_sorted) <= args.save_total_limit:\n","        return\n","\n","    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n","    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n","    for checkpoint in checkpoints_to_be_deleted:\n","        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n","        shutil.rmtree(checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsUEqcZNFmZp"},"outputs":[],"source":["#collapse\n","# Training of model\n","\n","def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n","    \"\"\" Train the model \"\"\"\n","    if args.local_rank in [-1, 0]:\n","        tb_writer = SummaryWriter()\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n","    train_dataloader = DataLoader(\n","        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    if args.max_steps > 0:\n","        t_total = args.max_steps\n","        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","    else:\n","        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n","    model.resize_token_embeddings(len(tokenizer))\n","    # add_special_tokens_(model, tokenizer)\n","\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": args.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","    )\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if (\n","        args.model_name_or_path\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n","    ):\n","        # Load in optimizer and scheduler states\n","        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n","\n","    if args.fp16:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n","\n","    # multi-gpu training (should be after apex fp16 initialization)\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Distributed training (should be after apex fp16 initialization)\n","    if args.local_rank != -1:\n","        model = torch.nn.parallel.DistributedDataParallel(\n","            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n","        )\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n","    logger.info(\n","        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n","        args.train_batch_size\n","        * args.gradient_accumulation_steps\n","        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n","    )\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    epochs_trained = 0\n","    steps_trained_in_current_epoch = 0\n","    # Check if continuing training from a checkpoint\n","    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n","        try:\n","            # set global_step to gobal_step of last saved checkpoint from model path\n","            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n","            global_step = int(checkpoint_suffix)\n","            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n","            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n","\n","            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n","            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n","            logger.info(\"  Continuing training from global step %d\", global_step)\n","            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n","        except ValueError:\n","            logger.info(\"  Starting fine-tuning.\")\n","\n","    tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","    train_iterator = trange(\n","        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n","    )\n","    set_seed(args)  # Added here for reproducibility\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n","        for step, batch in enumerate(epoch_iterator):\n","\n","            # Skip past any already trained steps if resuming training\n","            if steps_trained_in_current_epoch > 0:\n","                steps_trained_in_current_epoch -= 1\n","                continue\n","\n","            inputs, labels = (batch, batch)\n","            if inputs.shape[1] > 1024: continue\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            model.train()\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n","\n","            if args.n_gpu > 1:\n","                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            if args.fp16:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            tr_loss += loss.item()\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                if args.fp16:\n","                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                else:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n","                    # Log metrics\n","                    if (\n","                        args.local_rank == -1 and args.evaluate_during_training\n","                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(args, model, tokenizer)\n","                        for key, value in results.items():\n","                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n","                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                    logging_loss = tr_loss\n","\n","                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n","                    checkpoint_prefix = \"checkpoint\"\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n","                    os.makedirs(output_dir, exist_ok=True)\n","                    model_to_save = (\n","                        model.module if hasattr(model, \"module\") else model\n","                    )  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","\n","                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","                    _rotate_checkpoints(args, checkpoint_prefix)\n","\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n","\n","            if args.max_steps > 0 and global_step > args.max_steps:\n","                epoch_iterator.close()\n","                break\n","        if args.max_steps > 0 and global_step > args.max_steps:\n","            train_iterator.close()\n","            break\n","\n","    if args.local_rank in [-1, 0]:\n","        tb_writer.close()\n","\n","    return global_step, tr_loss / global_step\n","\n","# Evaluation of some model\n","\n","def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args.output_dir\n","\n","    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n","    os.makedirs(eval_output_dir, exist_ok=True)\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(\n","        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    # multi-gpu evaluate\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        inputs, labels = (batch, batch)\n","        inputs = inputs.to(args.device)\n","        labels = labels.to(args.device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs, labels=labels)\n","            lm_loss = outputs[0]\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\"perplexity\": perplexity}\n","\n","    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RS3Nav2-FsKy"},"outputs":[],"source":["#collapse\n","# Main show runner\n","\n","def main(df_trn, df_val):\n","    args = Args()\n","    \n","    if args.should_continue:\n","        sorted_checkpoints = _sorted_checkpoints(args)\n","        if len(sorted_checkpoints) == 0:\n","            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n","        else:\n","            args.model_name_or_path = sorted_checkpoints[-1]\n","\n","    if (\n","        os.path.exists(args.output_dir)\n","        and os.listdir(args.output_dir)\n","        and args.do_train\n","        and not args.overwrite_output_dir\n","        and not args.should_continue\n","    ):\n","        raise ValueError(\n","            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n","                args.output_dir\n","            )\n","        )\n","\n","    # Setup CUDA, GPU & distributed training\n","    device = torch.device(\"cuda\")\n","    args.n_gpu = torch.cuda.device_count()\n","    args.device = device\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        args.local_rank,\n","        device,\n","        args.n_gpu,\n","        bool(args.local_rank != -1),\n","        args.fp16,\n","    )\n","\n","    # Set seed\n","    set_seed(args)\n","\n","    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n","    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n","    model = AutoModelWithLMHead.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=False,\n","        config=config,\n","        cache_dir=args.cache_dir,\n","    )\n","    model.to(args.device)\n","    \n","    logger.info(\"Training/evaluation parameters %s\", args)\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n","\n","        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n","    if args.do_train:\n","        # Create output directory if needed\n","        os.makedirs(args.output_dir, exist_ok=True)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n","        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n","            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n","\n","            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["af36eb4d2b4b44588f31731634aa9647","f09b7e1fb0074442aef2fa5975cbbf95","9b25ab63561145a0a08e673d7342bf02","4f3658370c33497d82e13620514597c8","0fd402d18cbb40b980566d8579d598d2","d8f5d9e6430946a6aa2ecc67f8476ad3","b16ff1001969466caec7ed3d4c01494e","bf44339c1b64459ea67d0bdedabf6432","529abd94757548efad4e5a526c39c791","0cf4ee9c78e94e8fb81e68c02bc7cfe7","95a82ab0b77743c6a1ebbb5524cd7bb6","7745f19233fe4e0dbc337fd8191b56ad","0a86f3880a5f462db0b821607b1075b8","06c308fa2993435f904019701f8dfbe4","ec4eab6d018f4454a124855cc56179b8","ade4f09823ce496bb58dc2576f3e37cc","b49de81a2db04d2a89bf53ab09e1fbcd","b1edc2b6aad04973921755485618828e","21bc7f97e2924a36bd2988921b2ca824","7b465ade52744bc1a75d0c2cecf879be","b8268a1ef4b548409a823abaa6acf999","64e4887e1fb449a59eaa52d0adb4fca8","574da585455e4a5a8b2b959df67a9424","1e2611f144284f629e2d01982a55cf54","5868e605449043859e2f268d1ff6df8d","bbe286cc97f74ea0b53a42876ffda52c","e3f435ce446a49b98a7ae83395a616e8","65d773571d2b404c81d180a94cb0230e","67b0b8781210430589510db1e9254512","ddc22cb520174656b337dbd489a32741","bc4897d4232b4bd499ef414ba05dbf61","df0323948e7a4dfcaa01514e362d9d23","4cbe03b36479467f907d6b61544dbd01","c5bd6f291ada456d8ef9c9dcce08da5f","55f276a2af714df496de3c0c8fb5a4dd","0521bf163b874160b60ec9ab30460e34","5c15bc7179dd4490b9ace289b0c001a8","d7dcdd398a5f431f8c0b17e546e0aad2","d20874462b8d4ec5a3c34abed34caffb","e9ed1fabd3e1418ba7891e3e21852ed2","9dd61321b60a4163a98d51998583d614","6633c28ac775469387608fca1ab41122","dff9a10ff2df4fcfaee590adb5de021d","42013e54009e4d1ab73ec69f4c219ab9","a58e9283bd944a37b6ba3486d5f12e24","0c7e7d5ff1ef4dcaacc67216242f9a25","ce10169a24174b258c02d206fa40ac9d","1fc1737c6aa94d96bc14228522cc7aea","f8e5a0a50eb74d4cb4a804bff6d31ab8","f8d9e34c24794ee2a8ab1d1fda9d8a0a","9e21664cba3447e2a1a6442a8cadddb4","574021608ab8478399601a29bfaccf5f","a1d700b284894333b6f5780fb7938f4c","ab948e733de547b6880e90f56b1e6997","b30fe0c917934d0fbaf908205ebd3f42","a14db85be72e4ab0bb1b98ad94958672","a1219a989b1446d4935a64a3c9c19ca6","67dda9892e084b44a2b1f62994c5c858","308540b62da943a59e9dcbfc43dab1a7","9dc5781a2acb4a109743cc478bd1e5c3","3aa7f8a928de46bc84e4f24d8df14acf","5d6a9b17d23d40e38d5f8ba434c50cac","24a9e1ccd98143c296073fae326e8868","7ce85d8ef32f420a8f6008c9a952cca9","41b69cddc2234c0b980eae92b55d8e4b","651e51f9727b454a878e9eeeec522ed1"]},"id":"eajDrSWqHQBC","outputId":"faaa6095-a814-4f3c-b59e-c52d97c9022e","executionInfo":{"status":"ok","timestamp":1646446997210,"user_tz":-330,"elapsed":3124762,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["03/05/2022 01:31:11 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","03/05/2022 01:31:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.36332ed8c811a8f0488055ce93ce78909e2f8e027955fba2faa82bfc6728105b\n","03/05/2022 01:31:11 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 01:31:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.36332ed8c811a8f0488055ce93ce78909e2f8e027955fba2faa82bfc6728105b\n","03/05/2022 01:31:11 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 01:31:11 - INFO - transformers.tokenization_utils -   Model name 'microsoft/DialoGPT-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'microsoft/DialoGPT-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n","03/05/2022 01:31:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json from cache at cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","03/05/2022 01:31:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt from cache at cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","03/05/2022 01:31:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/added_tokens.json from cache at None\n","03/05/2022 01:31:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/special_tokens_map.json from cache at None\n","03/05/2022 01:31:13 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer_config.json from cache at None\n","03/05/2022 01:31:13 - INFO - transformers.file_utils -   https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin not found in cache or force_download set to True, downloading to /content/cached/tmpljrs9agx\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af36eb4d2b4b44588f31731634aa9647","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/351M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["03/05/2022 01:31:25 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin in cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n","03/05/2022 01:31:25 - INFO - transformers.file_utils -   creating metadata file for cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n","03/05/2022 01:31:25 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin from cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n","03/05/2022 01:31:29 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n","03/05/2022 01:31:42 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f2b954f8390>\n","03/05/2022 01:31:42 - INFO - __main__ -   Creating features from dataset file at cached\n","03/05/2022 01:32:07 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n","03/05/2022 01:32:07 - INFO - __main__ -   ***** Running training *****\n","03/05/2022 01:32:07 - INFO - __main__ -     Num examples = 15582\n","03/05/2022 01:32:07 - INFO - __main__ -     Num Epochs = 3\n","03/05/2022 01:32:07 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","03/05/2022 01:32:07 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","03/05/2022 01:32:07 - INFO - __main__ -     Gradient Accumulation steps = 1\n","03/05/2022 01:32:07 - INFO - __main__ -     Total optimization steps = 11685\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7745f19233fe4e0dbc337fd8191b56ad","version_minor":0,"version_major":2},"text/plain":["Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"574da585455e4a5a8b2b959df67a9424","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/3895 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/modeling_gpt2.py:148: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n","  w = torch.where(mask, w, self.masked_bias)\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n","  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","03/05/2022 01:46:55 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-3500/config.json\n","03/05/2022 01:46:57 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-3500/pytorch_model.bin\n","03/05/2022 01:46:57 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-3500\n","03/05/2022 01:47:01 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-3500\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5bd6f291ada456d8ef9c9dcce08da5f","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/3895 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["03/05/2022 02:01:45 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-7000/config.json\n","03/05/2022 02:01:46 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-7000/pytorch_model.bin\n","03/05/2022 02:01:47 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-7000\n","03/05/2022 02:01:51 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-7000\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a58e9283bd944a37b6ba3486d5f12e24","version_minor":0,"version_major":2},"text/plain":["Iteration:   0%|          | 0/3895 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["03/05/2022 02:16:37 - INFO - transformers.configuration_utils -   Configuration saved in output/checkpoint-10500/config.json\n","03/05/2022 02:16:39 - INFO - transformers.modeling_utils -   Model weights saved in output/checkpoint-10500/pytorch_model.bin\n","03/05/2022 02:16:39 - INFO - __main__ -   Saving model checkpoint to output/checkpoint-10500\n","03/05/2022 02:16:43 - INFO - __main__ -   Saving optimizer and scheduler states to output/checkpoint-10500\n","03/05/2022 02:21:40 - INFO - __main__ -    global_step = 11685, average loss = 1.8872064640647486\n","03/05/2022 02:21:40 - INFO - __main__ -   Saving model checkpoint to output\n","03/05/2022 02:21:40 - INFO - transformers.configuration_utils -   Configuration saved in output/config.json\n","03/05/2022 02:21:42 - INFO - transformers.modeling_utils -   Model weights saved in output/pytorch_model.bin\n","03/05/2022 02:21:42 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","03/05/2022 02:21:42 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 02:21:42 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n","03/05/2022 02:21:46 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","03/05/2022 02:21:46 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   loading file output/vocab.json\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   loading file output/merges.txt\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   loading file None\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n","03/05/2022 02:21:46 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n","03/05/2022 02:21:46 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n","03/05/2022 02:21:46 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","03/05/2022 02:21:47 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 02:21:47 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n","03/05/2022 02:21:51 - INFO - __main__ -   Creating features from dataset file at cached\n","03/05/2022 02:21:57 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n","03/05/2022 02:21:58 - INFO - __main__ -   ***** Running evaluation  *****\n","03/05/2022 02:21:58 - INFO - __main__ -     Num examples = 3918\n","03/05/2022 02:21:58 - INFO - __main__ -     Batch size = 4\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a14db85be72e4ab0bb1b98ad94958672","version_minor":0,"version_major":2},"text/plain":["Evaluating:   0%|          | 0/979 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["03/05/2022 02:23:15 - INFO - __main__ -   ***** Eval results  *****\n","03/05/2022 02:23:15 - INFO - __main__ -     perplexity = tensor(5.7337)\n"]},{"output_type":"execute_result","data":{"text/plain":["{'perplexity_': tensor(5.7337)}"]},"metadata":{},"execution_count":26}],"source":["main(trn_df,val_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":821},"id":"F9cvTkrnFwAr","outputId":"0044f523-7136-43be-bd13-648be174724f","executionInfo":{"status":"ok","timestamp":1646447006467,"user_tz":-330,"elapsed":9265,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}}},"outputs":[],"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_theyKAGFzwj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646448508551,"user_tz":-330,"elapsed":408674,"user":{"displayName":"NLP- RL","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18271151002131783103"}},"outputId":"0845398c-f0ad-4ccd-cc78-75cbb37c60f4"},"outputs":[{"output_type":"stream","name":"stderr","text":["03/05/2022 02:41:39 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at /root/.cache/torch/transformers/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.36332ed8c811a8f0488055ce93ce78909e2f8e027955fba2faa82bfc6728105b\n","03/05/2022 02:41:39 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 02:41:39 - INFO - transformers.tokenization_utils -   Model name 'microsoft/DialoGPT-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'microsoft/DialoGPT-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n","03/05/2022 02:41:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json from cache at /root/.cache/torch/transformers/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","03/05/2022 02:41:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt from cache at /root/.cache/torch/transformers/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","03/05/2022 02:41:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/added_tokens.json from cache at None\n","03/05/2022 02:41:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/special_tokens_map.json from cache at None\n","03/05/2022 02:41:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer_config.json from cache at None\n","03/05/2022 02:41:40 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n","03/05/2022 02:41:40 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"conversational\": {\n","      \"max_length\": 1000\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","03/05/2022 02:41:40 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n"]},{"output_type":"stream","name":"stdout","text":[">> User:Hi doctor,I am just wondering what is abutting and abutment of the nerve root means in a back issue. Please explain. What treatment is required forÂ annular bulging and tear?\n","DialoGPT: doctor: Hi. For further information consult a neurologist online --> https://www.icliniq.com/ask-a-doctor-online/neurologist\n",">> User:I am a 26 year old male. I am 5 feet and 9 inches tall and weigh 255 pounds. When I eat spicyÂ food, I poop blood. Sometimes when I have constipation as well, I poop a little bit of blood. I am really scared that I have colon cancer. I do have diarrhea often. IÂ do not have aÂ family history of colonÂ cancer. I got blood tests done last night. Please find my reports attached.\n","DialoGPT: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",">> User:I am 27 years old. My weight is 48 kg, and height is 5.8 feet. I am a pure vegetarian. I need to increase my body weight. I am suffering from psychological problems like anxiety. I am not diabetic, BP is normal. I do not smoke and drink. Please suggest foods to increase weight, immunity, and fertility. Kindly advise.\n","DialoGPT: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",">> User:I am a 39-year-old woman. I have mild pain in the left side of the chest (below the neck and above the breast) and then sensation in the upper back from four days. It comes and goes. Sometimes it goes to the right side of the chest also.\n","DialoGPT: What is the frequency of the pain? Is it continuous or intermittent? Is it persistent? Is it persistent for more than a week?\n",">> User:I am a 22-year-old female who was diagnosed with hypothyroidism (genetic) when I was 12. Over the past five years, I have become around 50 pounds overweight and all of my attempts to lose have seemed to fail so I have given up, but my weight has stayed the same. There is so much information put there about losing weight with hypothyroidism but it all seems to conflict. I am so unsure as to what type of exercise and diet I should follow as a result but I still would like to lose weight, but most importantly have my body feel better. What can I do?\n","DialoGPT: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",">> User:I was diagnosed with PCOS in January so my gynecologist prescribed me Ginette 35 for six months and Bonemac D3 for one month. But from March my periods are regular without taking medicines but there is sometimes slight pain in my lower abdomen and side abdomen. Should I continue medicines despite having normal and regular periods?\n","DialoGPT: doctor: Hi. I have gone through your query and understand your concern. I would like to know a few more details about your symptoms. For more information consult an obstetrician and gynaecologist online --> https://www.icliniq.com/ask-a-doctor-online/obstetrician-and-gynaecologist\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n","model = AutoModelWithLMHead.from_pretrained('output')\n","\n","# Let's chat for 5 lines\n","for step in range(6):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n","    # print(new_user_input_ids)\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(\n","        bot_input_ids, max_length=1000,\n","        pad_token_id=tokenizer.eos_token_id,\n","        top_p=0.92, top_k = 50\n","    )\n","    \n","    # pretty print last ouput tokens from bot\n","    print(\">> DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jW4oTMeDGDzP"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a7211330437f499ebbb62766b475d7f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b47bdb844079463cbeefebf365ed7bc2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fca5b45ccfef4ed88a31fcf37ec26263","IPY_MODEL_a8920166d7c94ccc8c52b971076e59f1","IPY_MODEL_dd5848ba096c4cd39d57e714679ffc3a"]}},"b47bdb844079463cbeefebf365ed7bc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fca5b45ccfef4ed88a31fcf37ec26263":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad465b67670949579758ad0e305cfa4e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a42581ccc09c4bef9c2ca961761951a6"}},"a8920166d7c94ccc8c52b971076e59f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_85a47e2bdfa040598b5af5cf8303723b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":641,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":641,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1a2574687c224a7ba2aac4006f36dbc5"}},"dd5848ba096c4cd39d57e714679ffc3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfabaa20f7564b29924273199b186dea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 641/641 [00:00&lt;00:00, 15.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34045a64e62d4636a7adda0e50efb82a"}},"ad465b67670949579758ad0e305cfa4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a42581ccc09c4bef9c2ca961761951a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85a47e2bdfa040598b5af5cf8303723b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1a2574687c224a7ba2aac4006f36dbc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfabaa20f7564b29924273199b186dea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"34045a64e62d4636a7adda0e50efb82a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31689cab58374e24a39c452dc1143079":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f3753f2ddbdf4951bd7d5d5fd8a9e248","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4ca0df277ba9498e91090faf1ed7910e","IPY_MODEL_387444066e834ffa9d6707c07f9c1bdc","IPY_MODEL_0c43a988e7c8426eab81eb4b84895414"]}},"f3753f2ddbdf4951bd7d5d5fd8a9e248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ca0df277ba9498e91090faf1ed7910e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_43dcbbc32b3642f08b8a71ea0b7515ea","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b729157638c4c83b4f658a3708d6cb9"}},"387444066e834ffa9d6707c07f9c1bdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_52040aad026548d3a503374df3187c78","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5a308162274422187f0556aaa66a107"}},"0c43a988e7c8426eab81eb4b84895414":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aa90481a9d98486d8287a11e0ea477f7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:00&lt;00:00, 1.08MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73b1f42107ba44d7b96266bb18eaa979"}},"43dcbbc32b3642f08b8a71ea0b7515ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b729157638c4c83b4f658a3708d6cb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"52040aad026548d3a503374df3187c78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a5a308162274422187f0556aaa66a107":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa90481a9d98486d8287a11e0ea477f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"73b1f42107ba44d7b96266bb18eaa979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62de908ed03c49e384582a3761081fb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ac3c63b395574dca85c096aa2c0c840e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d57651c3cfb84c9fa1fd760092a48b08","IPY_MODEL_21a83f0e03f44c4cbf3623c2ed7b9229","IPY_MODEL_4568e5e114a240a4b0c09c4e7cfd3002"]}},"ac3c63b395574dca85c096aa2c0c840e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d57651c3cfb84c9fa1fd760092a48b08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f45f5d19085843f4846924b2b11f625c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ab6267d49e94383b17ce43ee9051e12"}},"21a83f0e03f44c4cbf3623c2ed7b9229":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3ed21bde17d941089cd2a35c81134b79","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3ad32ccea414bc99e49ee6fd40c9b8d"}},"4568e5e114a240a4b0c09c4e7cfd3002":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d6e24f78d8294252b2cc930d67cc3c0a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 831kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c0b69f3c24943c89f3e61d8f5d45b4f"}},"f45f5d19085843f4846924b2b11f625c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6ab6267d49e94383b17ce43ee9051e12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3ed21bde17d941089cd2a35c81134b79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e3ad32ccea414bc99e49ee6fd40c9b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d6e24f78d8294252b2cc930d67cc3c0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2c0b69f3c24943c89f3e61d8f5d45b4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af36eb4d2b4b44588f31731634aa9647":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f09b7e1fb0074442aef2fa5975cbbf95","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b25ab63561145a0a08e673d7342bf02","IPY_MODEL_4f3658370c33497d82e13620514597c8","IPY_MODEL_0fd402d18cbb40b980566d8579d598d2"]}},"f09b7e1fb0074442aef2fa5975cbbf95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b25ab63561145a0a08e673d7342bf02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8f5d9e6430946a6aa2ecc67f8476ad3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b16ff1001969466caec7ed3d4c01494e"}},"4f3658370c33497d82e13620514597c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bf44339c1b64459ea67d0bdedabf6432","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":351265583,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":351265583,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_529abd94757548efad4e5a526c39c791"}},"0fd402d18cbb40b980566d8579d598d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0cf4ee9c78e94e8fb81e68c02bc7cfe7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 351M/351M [00:11&lt;00:00, 27.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95a82ab0b77743c6a1ebbb5524cd7bb6"}},"d8f5d9e6430946a6aa2ecc67f8476ad3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b16ff1001969466caec7ed3d4c01494e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf44339c1b64459ea67d0bdedabf6432":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"529abd94757548efad4e5a526c39c791":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0cf4ee9c78e94e8fb81e68c02bc7cfe7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95a82ab0b77743c6a1ebbb5524cd7bb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7745f19233fe4e0dbc337fd8191b56ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a86f3880a5f462db0b821607b1075b8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_06c308fa2993435f904019701f8dfbe4","IPY_MODEL_ec4eab6d018f4454a124855cc56179b8","IPY_MODEL_ade4f09823ce496bb58dc2576f3e37cc"]}},"0a86f3880a5f462db0b821607b1075b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06c308fa2993435f904019701f8dfbe4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b49de81a2db04d2a89bf53ab09e1fbcd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1edc2b6aad04973921755485618828e"}},"ec4eab6d018f4454a124855cc56179b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_21bc7f97e2924a36bd2988921b2ca824","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7b465ade52744bc1a75d0c2cecf879be"}},"ade4f09823ce496bb58dc2576f3e37cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8268a1ef4b548409a823abaa6acf999","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [49:33&lt;00:00, 990.28s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64e4887e1fb449a59eaa52d0adb4fca8"}},"b49de81a2db04d2a89bf53ab09e1fbcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b1edc2b6aad04973921755485618828e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21bc7f97e2924a36bd2988921b2ca824":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7b465ade52744bc1a75d0c2cecf879be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8268a1ef4b548409a823abaa6acf999":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64e4887e1fb449a59eaa52d0adb4fca8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"574da585455e4a5a8b2b959df67a9424":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1e2611f144284f629e2d01982a55cf54","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5868e605449043859e2f268d1ff6df8d","IPY_MODEL_bbe286cc97f74ea0b53a42876ffda52c","IPY_MODEL_e3f435ce446a49b98a7ae83395a616e8"]}},"1e2611f144284f629e2d01982a55cf54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5868e605449043859e2f268d1ff6df8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_65d773571d2b404c81d180a94cb0230e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Iteration: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67b0b8781210430589510db1e9254512"}},"bbe286cc97f74ea0b53a42876ffda52c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ddc22cb520174656b337dbd489a32741","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3895,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3895,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc4897d4232b4bd499ef414ba05dbf61"}},"e3f435ce446a49b98a7ae83395a616e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df0323948e7a4dfcaa01514e362d9d23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3895/3895 [16:33&lt;00:00,  3.74it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4cbe03b36479467f907d6b61544dbd01"}},"65d773571d2b404c81d180a94cb0230e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"67b0b8781210430589510db1e9254512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ddc22cb520174656b337dbd489a32741":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bc4897d4232b4bd499ef414ba05dbf61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df0323948e7a4dfcaa01514e362d9d23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4cbe03b36479467f907d6b61544dbd01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5bd6f291ada456d8ef9c9dcce08da5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_55f276a2af714df496de3c0c8fb5a4dd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0521bf163b874160b60ec9ab30460e34","IPY_MODEL_5c15bc7179dd4490b9ace289b0c001a8","IPY_MODEL_d7dcdd398a5f431f8c0b17e546e0aad2"]}},"55f276a2af714df496de3c0c8fb5a4dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0521bf163b874160b60ec9ab30460e34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d20874462b8d4ec5a3c34abed34caffb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Iteration: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9ed1fabd3e1418ba7891e3e21852ed2"}},"5c15bc7179dd4490b9ace289b0c001a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9dd61321b60a4163a98d51998583d614","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3895,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3895,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6633c28ac775469387608fca1ab41122"}},"d7dcdd398a5f431f8c0b17e546e0aad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dff9a10ff2df4fcfaee590adb5de021d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3895/3895 [16:32&lt;00:00,  3.22it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42013e54009e4d1ab73ec69f4c219ab9"}},"d20874462b8d4ec5a3c34abed34caffb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9ed1fabd3e1418ba7891e3e21852ed2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9dd61321b60a4163a98d51998583d614":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6633c28ac775469387608fca1ab41122":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dff9a10ff2df4fcfaee590adb5de021d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"42013e54009e4d1ab73ec69f4c219ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a58e9283bd944a37b6ba3486d5f12e24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0c7e7d5ff1ef4dcaacc67216242f9a25","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ce10169a24174b258c02d206fa40ac9d","IPY_MODEL_1fc1737c6aa94d96bc14228522cc7aea","IPY_MODEL_f8e5a0a50eb74d4cb4a804bff6d31ab8"]}},"0c7e7d5ff1ef4dcaacc67216242f9a25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce10169a24174b258c02d206fa40ac9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f8d9e34c24794ee2a8ab1d1fda9d8a0a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Iteration: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9e21664cba3447e2a1a6442a8cadddb4"}},"1fc1737c6aa94d96bc14228522cc7aea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_574021608ab8478399601a29bfaccf5f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3895,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3895,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1d700b284894333b6f5780fb7938f4c"}},"f8e5a0a50eb74d4cb4a804bff6d31ab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab948e733de547b6880e90f56b1e6997","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3895/3895 [16:27&lt;00:00,  4.56it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b30fe0c917934d0fbaf908205ebd3f42"}},"f8d9e34c24794ee2a8ab1d1fda9d8a0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9e21664cba3447e2a1a6442a8cadddb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"574021608ab8478399601a29bfaccf5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a1d700b284894333b6f5780fb7938f4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab948e733de547b6880e90f56b1e6997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b30fe0c917934d0fbaf908205ebd3f42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a14db85be72e4ab0bb1b98ad94958672":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a1219a989b1446d4935a64a3c9c19ca6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_67dda9892e084b44a2b1f62994c5c858","IPY_MODEL_308540b62da943a59e9dcbfc43dab1a7","IPY_MODEL_9dc5781a2acb4a109743cc478bd1e5c3"]}},"a1219a989b1446d4935a64a3c9c19ca6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67dda9892e084b44a2b1f62994c5c858":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3aa7f8a928de46bc84e4f24d8df14acf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Evaluating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d6a9b17d23d40e38d5f8ba434c50cac"}},"308540b62da943a59e9dcbfc43dab1a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_24a9e1ccd98143c296073fae326e8868","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":979,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":979,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ce85d8ef32f420a8f6008c9a952cca9"}},"9dc5781a2acb4a109743cc478bd1e5c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41b69cddc2234c0b980eae92b55d8e4b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 979/979 [01:17&lt;00:00, 13.17it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_651e51f9727b454a878e9eeeec522ed1"}},"3aa7f8a928de46bc84e4f24d8df14acf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d6a9b17d23d40e38d5f8ba434c50cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24a9e1ccd98143c296073fae326e8868":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7ce85d8ef32f420a8f6008c9a952cca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41b69cddc2234c0b980eae92b55d8e4b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"651e51f9727b454a878e9eeeec522ed1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}